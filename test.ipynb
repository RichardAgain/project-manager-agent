{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9a77ff92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"'(),-.01234567:;?ABCDEFGHIJLMNOPQRSTUVWXYZ]abcdefghijlmnopqrstuvxyz¡«»¿ÁÉÍÑÓÚàáéíïñóùúü\n",
      "Total number of character: 2097953\n"
     ]
    }
   ],
   "source": [
    "with open(\"input/quijote.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "chars = sorted(set(raw_text))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(\"Total number of character:\", len(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3c8442e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello pepe\n"
     ]
    }
   ],
   "source": [
    "string_to_int = { c:i for i, c in enumerate(chars) }\n",
    "int_to_string = { i:c for i, c in enumerate(chars) }\n",
    "encode = lambda strings : [string_to_int[c] for c in strings]\n",
    "decode = lambda ints : ''.join([int_to_string[i] for i in ints])\n",
    "\n",
    "encoded = encode(\"hello pepe\")\n",
    "print(decode(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f9bf634b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2097953]) torch.int64\n",
      "tensor([25, 57,  1, 55, 59, 53, 51, 59, 55, 60, 64, 60,  1, 54, 55, 50, 47, 57,\n",
      "        53, 60,  1, 50, 60, 59,  1, 36, 66, 55, 56, 60, 65, 51,  1, 50, 51,  1,\n",
      "        57, 47,  1, 32, 47, 59, 49, 54, 47,  0,  0,  0, 39, 21, 38, 21,  0,  0,\n",
      "        44, 60,  7,  1, 30, 66, 47, 59,  1, 27, 47, 57, 57, 60,  1, 50, 51,  1,\n",
      "        21, 59, 50, 63, 47, 50, 47,  7,  1, 51, 64, 49, 63, 55, 48, 47, 59, 60,\n",
      "         1, 50, 51,  1, 23, 82, 58, 47, 63, 47,  1, 50, 51, 57,  1, 37, 51, 69,\n",
      "         1, 59, 66, 51, 64, 65, 63, 60,  1, 64, 51, 86, 60, 63,  7,  1, 50, 51,\n",
      "         0, 57, 60, 64,  1, 62, 66, 51,  1, 63, 51, 64, 55, 50, 51, 59,  1, 51,\n",
      "        59,  1, 64, 66,  1, 23, 60, 59, 64, 51, 56, 60,  7,  1, 49, 51, 63, 65,\n",
      "        55, 52, 55, 49, 60,  1, 69,  1, 50, 60, 69,  1, 52, 51,  1, 62, 66, 51,\n",
      "         7,  1, 54, 47, 48, 55, 51, 59, 50, 60,  1, 67, 55, 64, 65, 60,  1, 61,\n",
      "        60, 63,  0, 57, 60, 64,  1, 64, 51, 86, 60, 63, 51, 64,  1, 50, 83, 57,\n",
      "         1, 66, 59,  1, 57, 55, 48, 63, 60,  1, 55, 59, 65, 55, 65, 66, 57, 47,\n",
      "        50, 60,  1, 25, 57,  1, 55, 59, 53, 51, 59, 55, 60, 64, 60,  1, 54, 55,\n",
      "        50, 47, 57, 53, 60,  1, 50, 51,  1, 57, 47,  1, 32, 47, 59, 49, 54, 47,\n",
      "         7,  0, 49, 60, 58, 61, 66, 51, 64, 65, 60,  1, 61, 60, 63,  1, 32, 55,\n",
      "        53, 66, 51, 57,  1, 50, 51,  1, 23, 51, 63, 67, 47, 59, 65, 51, 64,  1,\n",
      "        38, 47, 47, 67, 51, 50, 63, 47,  7,  1, 65, 47, 64, 47, 63, 60, 59,  1,\n",
      "        49, 47, 50, 47,  1, 61, 57, 55, 51, 53, 60,  1, 50, 51, 57,  1, 50, 55,\n",
      "        49, 54, 60,  0, 57, 55, 48, 63, 60,  1, 47,  1, 65, 63, 51, 64,  1, 58,\n",
      "        47, 63, 47, 67, 51, 50, 84, 64,  1, 69,  1, 58, 51, 50, 55, 60, 19,  1,\n",
      "        51, 57,  1, 49, 66, 47, 57,  1, 65, 55, 51, 59, 51,  1, 60, 49, 54, 51,\n",
      "        59, 65, 47,  1, 69,  1, 65, 63, 51, 64,  1, 61, 57, 55, 51, 53, 60, 64,\n",
      "         7,  1, 62, 66, 51,  0, 47, 57,  1, 50, 55, 49, 54, 60,  1, 61, 63, 51,\n",
      "        49, 55, 60,  1, 58, 60, 59, 65, 47,  1, 51, 57,  1, 50, 55, 49, 54, 60,\n",
      "         1, 57, 55, 48, 63, 60,  1, 50, 60, 49, 55, 51, 59, 65, 60, 64,  1, 69,\n",
      "         1, 59, 60, 67, 51, 59, 65, 47,  1, 58, 47, 63, 47, 67, 51, 50, 84, 64,\n",
      "         1, 69,  1, 58, 51, 50, 55, 60,  7,  0, 51, 59,  1, 62, 66, 51,  1, 64,\n",
      "        51,  1, 54, 47,  1, 50, 51,  1, 67, 51, 59, 50, 51, 63,  1, 51, 59,  1,\n",
      "        61, 47, 61, 51, 57, 19,  1, 69,  1, 50, 55, 51, 63, 60, 59,  1, 57, 55,\n",
      "        49, 51, 59, 49, 55, 47,  1, 61, 47, 63, 47,  1, 62, 66, 51,  1, 47,  1,\n",
      "        51, 64, 65, 51,  1, 61, 63, 51, 49, 55, 60,  0, 64, 51,  1, 61, 66, 51,\n",
      "        50, 47,  1, 67, 51, 59, 50, 51, 63,  7,  1, 69,  1, 58, 47, 59, 50, 47,\n",
      "        63, 60, 59,  1, 62, 66, 51,  1, 51, 64, 65, 47,  1, 65, 47, 64, 47,  1,\n",
      "        64, 51,  1, 61, 60, 59, 53, 47,  1, 47, 57,  1, 61, 63, 55, 59, 49, 55,\n",
      "        61, 55, 60,  1, 50, 51, 57,  1, 50, 55, 49, 54, 60,  0, 57, 55, 48, 63,\n",
      "        60,  7,  1, 69,  1, 59, 60,  1, 64, 51,  1, 61, 66, 51, 50, 47,  1, 67,\n",
      "        51, 59, 50, 51, 63,  1, 64, 55, 59,  1, 51, 57, 57, 47,  9,  1, 44,  7,\n",
      "         1, 61, 47, 63, 47,  1, 62, 66, 51,  1, 50, 51, 57, 57, 60,  1, 49, 60,\n",
      "        59, 64, 65, 51,  7,  1, 50, 55,  1, 57, 47,  0, 61, 63, 51, 64, 51, 59,\n",
      "        65, 51,  1, 51, 59,  1, 41, 47, 57, 57, 47, 50, 60, 57, 55, 50,  7,  1,\n",
      "        47,  1, 67, 51, 55, 59, 65, 51,  1, 50, 84, 47, 64,  1, 50, 51, 57,  1,\n",
      "        58, 51, 64,  1, 50, 51,  1, 50, 51, 49, 55, 51, 58, 48, 63, 51,  1, 50,\n",
      "        51,  1, 58, 55, 57,  1, 69,  0, 64, 51, 55, 64, 49, 55, 51, 59, 65, 60,\n",
      "        64,  1, 69,  1, 49, 66, 47, 65, 63, 60,  1, 47, 86, 60, 64,  9,  0,  0,\n",
      "        30, 66, 47, 59,  1, 27, 47, 57, 57, 60,  1, 50, 51,  1, 21, 59, 50, 63,\n",
      "        47, 50, 47,  9,  0,  0, 39, 25, 38, 39, 29, 32, 34, 33, 29, 34,  1, 24,\n",
      "        25,  1, 31, 21, 38,  1, 25, 37, 37, 21, 39, 21, 38,  0,  0, 25, 64, 65,\n",
      "        51,  1, 57, 55, 48, 63, 60,  1, 59, 60,  1, 65, 55, 51, 59, 51,  1, 49,\n",
      "        60, 64, 47,  1, 50, 55, 53, 59, 47,  1, 62, 66, 51,  1, 59, 60,  1, 49,\n",
      "        60, 63, 63, 51, 64, 61, 60, 59, 50, 47,  1, 47,  1, 64, 66,  1, 60, 63,\n",
      "        55, 53, 55, 59, 47, 57, 19,  1, 51, 59,  0, 65, 51, 64, 65, 55, 58, 60,\n",
      "        59, 55, 60,  1, 50, 51,  1, 57, 60,  1, 54, 47, 48, 51, 63,  1, 49, 60,\n",
      "        63, 63, 51, 49, 65, 60,  7,  1, 50, 55,  1, 51, 64, 65, 47,  1, 52, 51,\n",
      "        51,  9,  1, 25, 59,  1, 51, 57,  1, 23, 60, 57, 51, 53, 55, 60,  1, 50,\n",
      "        51,  1, 57, 47,  1, 32, 47, 50, 63, 51])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(raw_text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5da6d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "845061e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25, 57,  1, 55, 59, 53, 51, 59, 55])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ba31d9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([25]) the target: 57\n",
      "when input is tensor([25, 57]) the target: 1\n",
      "when input is tensor([25, 57,  1]) the target: 55\n",
      "when input is tensor([25, 57,  1, 55]) the target: 59\n",
      "when input is tensor([25, 57,  1, 55, 59]) the target: 53\n",
      "when input is tensor([25, 57,  1, 55, 59, 53]) the target: 51\n",
      "when input is tensor([25, 57,  1, 55, 59, 53, 51]) the target: 59\n",
      "when input is tensor([25, 57,  1, 55, 59, 53, 51, 59]) the target: 55\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2892488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[48, 84, 47,  1, 48, 66, 63, 57],\n",
      "        [ 7,  1, 57, 51,  1, 61, 47, 63],\n",
      "        [51, 59, 65, 63, 51,  1, 50, 60],\n",
      "        [51, 59, 53, 47, 86, 51,  1, 47]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[84, 47,  1, 48, 66, 63, 57, 47],\n",
      "        [ 1, 57, 51,  1, 61, 47, 63, 51],\n",
      "        [59, 65, 63, 51,  1, 50, 60, 64],\n",
      "        [59, 53, 47, 86, 51,  1, 47,  1]])\n",
      "----------\n",
      "when input is tensor([48]) the target: 84\n",
      "when input is tensor([48, 84]) the target: 47\n",
      "when input is tensor([48, 84, 47]) the target: 1\n",
      "when input is tensor([48, 84, 47,  1]) the target: 48\n",
      "when input is tensor([48, 84, 47,  1, 48]) the target: 66\n",
      "when input is tensor([48, 84, 47,  1, 48, 66]) the target: 63\n",
      "when input is tensor([48, 84, 47,  1, 48, 66, 63]) the target: 57\n",
      "when input is tensor([48, 84, 47,  1, 48, 66, 63, 57]) the target: 47\n",
      "when input is tensor([7]) the target: 1\n",
      "when input is tensor([7, 1]) the target: 57\n",
      "when input is tensor([ 7,  1, 57]) the target: 51\n",
      "when input is tensor([ 7,  1, 57, 51]) the target: 1\n",
      "when input is tensor([ 7,  1, 57, 51,  1]) the target: 61\n",
      "when input is tensor([ 7,  1, 57, 51,  1, 61]) the target: 47\n",
      "when input is tensor([ 7,  1, 57, 51,  1, 61, 47]) the target: 63\n",
      "when input is tensor([ 7,  1, 57, 51,  1, 61, 47, 63]) the target: 51\n",
      "when input is tensor([51]) the target: 59\n",
      "when input is tensor([51, 59]) the target: 65\n",
      "when input is tensor([51, 59, 65]) the target: 63\n",
      "when input is tensor([51, 59, 65, 63]) the target: 51\n",
      "when input is tensor([51, 59, 65, 63, 51]) the target: 1\n",
      "when input is tensor([51, 59, 65, 63, 51,  1]) the target: 50\n",
      "when input is tensor([51, 59, 65, 63, 51,  1, 50]) the target: 60\n",
      "when input is tensor([51, 59, 65, 63, 51,  1, 50, 60]) the target: 64\n",
      "when input is tensor([51]) the target: 59\n",
      "when input is tensor([51, 59]) the target: 53\n",
      "when input is tensor([51, 59, 53]) the target: 47\n",
      "when input is tensor([51, 59, 53, 47]) the target: 86\n",
      "when input is tensor([51, 59, 53, 47, 86]) the target: 51\n",
      "when input is tensor([51, 59, 53, 47, 86, 51]) the target: 1\n",
      "when input is tensor([51, 59, 53, 47, 86, 51,  1]) the target: 47\n",
      "when input is tensor([51, 59, 53, 47, 86, 51,  1, 47]) the target: 1\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1200)\n",
    "batch_size = 4\n",
    "block_size = 8 \n",
    "\n",
    "def get_batch(split):\n",
    "   data = train_data if split == \"train\" else val_data\n",
    "   ix = torch.randint(len(data) - block_size, (batch_size,)) \n",
    "   x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "   y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "   return x, y\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "print(\"----------\")\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "974168c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[48, 84, 47,  1, 48, 66, 63, 57],\n",
       "        [ 7,  1, 57, 51,  1, 61, 47, 63],\n",
       "        [51, 59, 65, 63, 51,  1, 50, 60],\n",
       "        [51, 59, 53, 47, 86, 51,  1, 47]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6cdafd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 91])\n",
      "tensor(4.9582, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "ZxhTAÍüÚùàÚÁvo.s»bjRT'6!íDzÓy,tttóIBS ¿g5Zóe0gF». -]3!1É¿LT¡ÚfàLWpRa4EÓhX?óIó¡Ú,7dÚ2!vnIàD?Á«üg;XDY4\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1200)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C  = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1,:]\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim = 1)\n",
    "        return idx\n",
    "        \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx= torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "56bd2381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8c6f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.318368434906006\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range (10000):\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8999937f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-Po due avan RRosalisuerión ese do nibrraradies que querer co  cumue lalla cos ado fue muer a bro ha\n"
     ]
    }
   ],
   "source": [
    "idx= torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
